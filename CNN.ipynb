{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network - Pattern Recognition in Stock Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "#import pandas_datareader as pdr\n",
    "import csv\n",
    "import warnings\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#hide all warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "#show all warnings just once\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SirLukeSchande/.pyenv/versions/3.6.10/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/SirLukeSchande/.pyenv/versions/3.6.10/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from helpers import delete_nans, get_returns, plot_example_returns, tickers, get_data_subsets#, data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = \"2007-01-01\"\n",
    "finish = \"2017-01-01\"\n",
    "\n",
    "#data_loader(begin, finish, 'returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with only NaNs: 0\n",
      "Number of lines with only NaNs: 0\n",
      "Number of NaNs: 0\n",
      "shape Dataframe: (2518, 20)\n"
     ]
    }
   ],
   "source": [
    "returns = get_returns('returns.csv', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_nans('returns.csv', 'returns.csv')\n",
    "plot_example_returns('returns.csv', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x_train, y_train, x_test, y_test, inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 40, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                     input_shape=inp_shape))\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    #Conv1D => 1D Convolution (Schaut nach Mustern)\n",
    "    #mit filters = Anzahl Weight Functions, kernel_size = Anzahl simultan betrachteter Felder, \n",
    "    #relu = 0 für value<0 sonst linear\n",
    "    \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    #Dropout sets randomly chosen values to 0 to prevent overfitting\n",
    "    \n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    #MaxPooling halbiert array Größe und nimmt größte Werte der Feature-Gewichtungen \n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    #Flatten reduziert dimensionen eines arrays auf niedrigst mögliche Dimension (1xdim) (überschreibt Nullen))\n",
    "    \n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    #Klassisches NN hinter Convolutional Layer geschaltet, lernt also im Feature Raum, durch Convolutional Net vorgebenen\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully(x_train,y_train,x_test,y_test,inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 1, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(100, activation='tanh'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dropout(.5))\n",
    "    model.add(layers.Dense(100, activation='tanh'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x_train, y_train, x_test, y_test, inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 40, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.GRU(42, input_shape = inp_shape, return_sequences = True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.GRU(42, return_sequences = False))\n",
    "    \n",
    "    #Dropout sets randomly chosen values to 0 to prevent overfitting\n",
    "    \n",
    "    #model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    #MaxPooling halbiert array Größe und nimmt größte Werte der Feature-Gewichtungen \n",
    "    \n",
    "    #model.add(layers.Flatten())\n",
    "    #Flatten reduziert dimensionen eines arrays auf niedrigst mögliche Dimension (1xdim) (überschreibt Nullen))\n",
    "    \n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    #Klassisches NN hinter Convolutional Layer geschaltet, lernt also im Feature Raum, durch Convolutional Net vorgebenen\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion get_data_subsets unterteilt die Matrix in eine Matrix der Dimension dur x N (Zeitfenster x Stocks) und korrespondierender Vektor für den Tag darauf (dur=1 x stocks). Jedes Matrix-Vektor Paar stellt einen Input plus Target Output(Label, Lösung) dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    inp_shape=(dur,N)\n",
    "    print(inp_shape)\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = cnn(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fully_connected(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    inp_shape=(dur,N)\n",
    "    print(inp_shape)\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    print(\"now\")\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = fully(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_rnn(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    inp_shape=(dur,N)\n",
    "    print(inp_shape)\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = rnn(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rnn,x_train,y_train,x_test,y_test = main_rnn(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_cnn,x_train,y_train,x_test,y_test = main(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_subsets(df,dur, variant='next_day'):\n",
    "    \"\"\" variant options: month, vola, next_day\n",
    "\n",
    "    \"\"\"\n",
    "    branches_ = pd.read_csv('snp500info.csv', index_col=0)\n",
    "    branches = branches_.drop(columns = ['Security', 'GICS Sub Industry', 'start at yahoo'])\n",
    "    \n",
    "    companies = list(df)\n",
    "    data_onehot = branches.loc[branches.index.isin(companies)].iloc[:,0]\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(data_onehot)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded).T\n",
    "\n",
    "    df = np.array(df)\n",
    "    month = 30\n",
    "    leng = df.shape[0]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(leng):\n",
    "        if dur+i>=leng:\n",
    "            print (i)\n",
    "            break\n",
    "        if variant == 'vola':\n",
    "            x.append(np.concatenate((onehot_encoded, np.abs(df[i:dur+i,:]))))\n",
    "            y.append(np.abs(df[dur+i,:]))\n",
    "        else:\n",
    "            x.append(np.concatenate((onehot_encoded, df[i:dur+i,:])))\n",
    "            if variant == 'month':\n",
    "                y.append(np.mean(df[dur+i:dur+i+month,:]))\n",
    "            elif variant == 'next_day':\n",
    "                y.append(df[dur+i,:])\n",
    "            else:\n",
    "                raise NameError(\"Use correct fun_label\")\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.45001632e-03, 5.47988177e-03, 0.00000000e+00,\n",
       "       1.04264553e-02, 2.08723434e-02, 7.58104829e-03, 1.64344193e-02,\n",
       "       3.53097933e-03, 8.03016405e-03, 4.75909676e-04, 6.90187933e-03,\n",
       "       1.89106898e-03, 1.60416830e-02, 4.79606808e-04, 1.75102019e-02,\n",
       "       1.62659412e-02, 3.94370482e-03, 2.12574863e-02, 6.84617478e-03,\n",
       "       1.75901434e-02, 1.86873235e-02, 6.90321122e-03, 4.01899266e-03,\n",
       "       5.65122284e-03, 3.07832916e-03, 1.16388616e-02, 5.63514926e-03,\n",
       "       3.50219487e-03, 2.10906634e-03, 8.41676806e-03, 4.70672643e-02,\n",
       "       7.78563343e-03, 9.80850575e-04, 1.29837138e-02, 3.40034387e-02,\n",
       "       1.10482793e-02, 1.06738983e-02, 6.67812933e-03, 2.06857201e-03,\n",
       "       1.75482378e-02, 1.87676270e-02, 2.48956472e-03, 3.97333103e-03,\n",
       "       1.09220105e-02, 2.03119651e-02, 6.06822690e-03, 2.26171776e-03,\n",
       "       5.28941267e-03, 7.51682278e-03, 1.49216438e-02, 1.46430645e-02,\n",
       "       6.46915974e-03, 4.94288059e-04, 2.46987033e-04, 5.19254529e-03,\n",
       "       1.09372502e-02, 5.27769269e-03, 3.49990929e-03, 4.23538317e-03,\n",
       "       1.43882175e-02, 5.13571600e-03, 1.70321333e-02, 1.10053887e-02,\n",
       "       1.49972634e-02, 2.45069656e-04, 9.57604310e-03, 1.45901605e-03,\n",
       "       2.42567047e-04, 4.85799487e-04, 5.58163342e-03, 4.14896153e-03,\n",
       "       5.34616513e-03, 9.66903551e-04, 5.79542787e-03, 5.28214237e-03,\n",
       "       4.05999878e-03, 5.94726074e-03, 3.54719895e-03, 1.85097959e-02,\n",
       "       2.33109009e-04, 2.32964525e-03, 2.24144983e-02, 2.28330362e-04,\n",
       "       2.76251280e-02, 1.77713240e-03, 5.78689596e-03, 1.27603197e-02,\n",
       "       4.86269478e-03, 5.99727486e-03, 1.02793896e-02, 7.52075164e-03,\n",
       "       6.46320958e-03, 1.43559969e-02, 7.96138422e-03, 1.09717131e-03,\n",
       "       5.04082051e-03, 4.84562858e-03, 1.31502730e-03, 2.41427032e-03,\n",
       "       8.76219376e-04, 2.18760758e-03, 3.71066723e-03, 1.30487158e-03,\n",
       "       2.39548389e-03, 1.34698197e-02, 8.14825969e-03, 6.27541603e-03,\n",
       "       1.80869086e-02, 9.76445643e-03, 3.73633238e-03, 8.76154191e-04,\n",
       "       3.93797726e-03, 2.17603294e-04, 1.87365515e-02, 1.02131427e-02,\n",
       "       7.03266841e-03, 5.31208896e-03, 6.67603715e-03, 1.23207376e-02,\n",
       "       1.28347735e-02, 2.24855508e-04, 1.27739189e-02, 8.63064774e-03,\n",
       "       7.02060560e-03, 1.74275758e-03, 1.34837998e-02, 9.25930123e-03,\n",
       "       1.57984556e-02, 3.72399225e-02, 2.11185553e-03, 4.02124172e-03,\n",
       "       1.47589370e-03, 7.78828387e-03, 2.67290225e-02, 2.89237652e-03,\n",
       "       2.26587133e-03, 1.69317226e-02, 1.47015127e-03, 9.25528057e-03,\n",
       "       1.35882102e-02, 6.88776570e-03, 2.38414927e-03, 1.52079651e-02,\n",
       "       3.20987938e-02, 1.70020713e-02, 2.21477438e-02, 4.12523940e-04,\n",
       "       1.89767594e-02, 4.81781749e-02, 4.04070691e-03, 2.58423643e-02,\n",
       "       2.37459682e-02, 2.38997155e-02, 2.16704599e-03, 2.38866935e-02,\n",
       "       1.20887690e-02, 1.22371785e-02, 8.91125013e-03, 2.64971389e-02,\n",
       "       9.44402302e-03, 6.44505127e-03, 1.90416656e-02, 3.28499895e-02,\n",
       "       4.13262954e-04, 1.87858803e-02, 1.60081256e-02, 7.97596100e-04,\n",
       "       1.79629628e-03, 2.66987709e-02, 6.70120156e-03, 1.77545770e-02,\n",
       "       2.22574761e-02, 2.05041607e-04, 7.99695264e-03, 1.57090052e-02,\n",
       "       2.09607960e-02, 7.77347712e-03, 6.42817418e-03, 8.58275992e-03,\n",
       "       5.73931295e-03, 1.47294180e-02, 7.06156736e-03, 6.91415374e-03,\n",
       "       9.54821171e-03, 2.39000082e-02, 1.17692789e-03, 1.33226270e-02,\n",
       "       2.18386220e-03, 8.52028519e-03, 2.22002244e-02, 8.26426856e-03,\n",
       "       4.00279200e-03, 1.22488400e-02, 1.16293329e-03, 6.01320722e-03,\n",
       "       5.26942637e-03, 1.99965594e-02, 6.28047576e-03, 2.78040033e-02,\n",
       "       2.13992432e-03])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = get_data_subsets(returns,200,\"vola\")\n",
    "x[1,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_fully,x_train,y_train,x_test,y_test = main_fully_connected(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fully.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_rnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check wether stock value changes were recognised to increase/decrease correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_goodness(model,x_new,y_new):\n",
    "    \"\"\"\n",
    "    directional goodnes gives the factor of correctly predicted signs of first order derivative of returns to false ones\n",
    "    oder auch: \n",
    "    gibt die Anzahl der Beobachtungen an, deren Vorhersage das richtige Vorzeichen hatte (Kurs steigt, Kurs fällt)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x_new)\n",
    "    count = 0\n",
    "    #print(y_new.shape)\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            p= y_pred[i,j] > 0\n",
    "            n = y_new[i,j] > 0\n",
    "            if n==p:\n",
    "                count +=1\n",
    "    print('percentage of correctly predicted directions of returns: ' + str(count/len(y_pred)/len(y_pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check internal goodness - predicted values vs actual measured values used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_goodness(model, x_new, y_new):\n",
    "    print('compare true to predicted values of internal validation on learned dataset: ')\n",
    "    y_pred = model.predict(x_new)\n",
    "    #model.predict nimmt x-werte und gibt die predicteten y-werte zurück\n",
    "    plt.scatter(y_new, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check external goodness - predicted values for future data vs actual future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_goodness(model, x_new, y_new):\n",
    "    print('compare true to predicted values of external validation set: ')\n",
    "    y_pred = model.predict(x_new)\n",
    "    color =  [\"r\", \"b\", \"g\"]\n",
    "    for i in range(3):\n",
    "        plt.plot(y_new[:100,i],c=color[i], label = 'true')\n",
    "        plt.plot(y_pred[:100,i], c=color[i], linestyle='--', label = 'pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    x_test2[:,:,i] = x_test[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn, x_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
